{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jglv0IG6O-Td"
   },
   "outputs": [],
   "source": [
    "PATH= './'\n",
    "LOGDIR = PATH+'MODELS/save_2'\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.core.protobuf import saver_pb2\n",
    "import model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0pvIczKwO-Tj",
    "outputId": "a1d04ca1-c97a-4d24-e01b-e09ff19e22a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "In-86p8bO-Tl"
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "L2NormConst = 0.001\n",
    "train_vars = tf.trainable_variables()\n",
    "loss = tf.reduce_mean(tf.square(tf.subtract(model.y_, model.y))) + tf.add_n([tf.nn.l2_loss(v) for v in train_vars]) * L2NormConst\n",
    "# equality = tf.equal(model.y, model.y_)\n",
    "# accuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2CH0bHt4O-To"
   },
   "outputs": [],
   "source": [
    "tf.summary.scalar(\"loss\", loss)\n",
    "# tf.summary.scalar(\"accuracy\", accuracy)\n",
    "# merge all summaries into a single op\n",
    "merged_summary_op =  tf.summary.merge_all()\n",
    "saver = tf.train.Saver(write_version = saver_pb2.SaverDef.V1)\n",
    "logs_path = PATH+'logs/'\n",
    "summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "\n",
    "epochs = 30\n",
    "batch_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n-a9APRoO-Tq"
   },
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "import random\n",
    "\n",
    "DataX = []\n",
    "DataY = []\n",
    "\n",
    "#points to the end of the last batch\n",
    "train_batch_pointer = 0\n",
    "val_batch_pointer = 0\n",
    "\n",
    "#read data.txt\n",
    "with open(PATH+\"Dataset/driving_dataset/data.txt\") as f:\n",
    "    for line in f:\n",
    "        DataX.append(PATH+\"Dataset/driving_dataset/\" + line.split()[0])\n",
    "        #the paper by Nvidia uses the inverse of the turning radius,\n",
    "        #but steering wheel angle is proportional to the inverse of turning radius\n",
    "        #so the steering wheel angle in radians is used as the output\n",
    "        DataY.append(float(line.split()[1]) * scipy.pi / 180)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J6yZTMhJO-Ts",
    "outputId": "fa61d1b3-3d51-46b2-a156-8ab8475dcdef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45406\n"
     ]
    }
   ],
   "source": [
    "#get number of images\n",
    "num_images = len(DataX)\n",
    "\n",
    "\n",
    "train_xs = DataX[:int(len(DataX) * 0.7)]\n",
    "train_ys = DataY[:int(len(DataY) * 0.7)]\n",
    "\n",
    "val_xs = DataX[-int(len(DataX) * 0.3):]\n",
    "val_ys = DataY[-int(len(DataY) * 0.3):]\n",
    "\n",
    "num_train_images = len(train_xs)\n",
    "num_val_images = len(val_xs)\n",
    "\n",
    "print(num_images)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OrXV3XaQO-Tu"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "def LoadTrainBatch(batch_size):\n",
    "    global train_batch_pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(0, batch_size):\n",
    "#         print(train_xs[(train_batch_pointer + i) % num_train_images])\n",
    "#         img= cv2.imread(train_xs[(train_batch_pointer + i) % num_train_images])\n",
    "#         print(type(img))\n",
    "        x_out.append(cv2.resize(cv2.imread(train_xs[(train_batch_pointer + i) % num_train_images])[-150:], (200,66)) / 255.0)\n",
    "        y_out.append([train_ys[(train_batch_pointer + i) % num_train_images]])\n",
    "    train_batch_pointer += batch_size\n",
    "    return x_out, y_out\n",
    "\n",
    "def LoadValBatch(batch_size):\n",
    "    global val_batch_pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(0, batch_size):\n",
    "        x_out.append(cv2.resize(cv2.imread(train_xs[(val_batch_pointer + i) % num_train_images])[-150:], (200,66)) / 255.0)\n",
    "        y_out.append([val_ys[(val_batch_pointer + i) % num_val_images]])\n",
    "    val_batch_pointer += batch_size\n",
    "    return x_out, y_out\n",
    "\n",
    "# train_range= int(math.ceil((num_images*0.7)/(batch_size*5)))\n",
    "# val_range=int((int((num_images)/(batch_size))-(train_range*5))/5)\n",
    "# print(type(train_range),type(val_range))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W4Fm0yNIO-Tv",
    "outputId": "3174d776-fd6c-4a49-b3dc-ee398e3a45d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "num= (int)(num_images/(batch_size*5))\n",
    "print(num)\n",
    "print(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1JWp67qYO-Tz",
    "outputId": "815e96d7-1815-4101-b1f7-bcae179376b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 1.26383e+06\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 57666\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 14662.2\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 8096.68\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 3420.79\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 640.214\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 231.936\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 1076.34\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 27.4982\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 15:48:51.226569 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 15:48:51.227378 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 15:48:51.227991 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 15:48:51.228662 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 15:48:51.229418 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 15:48:51.230033 139782624093952 saver.py:1145] *******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 0, Loss: 27.4982\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v0.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 149.784\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 205.709\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 520.227\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 477.006\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 50.4183\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 13.7381\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 114.082\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 36.1341\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 22.0047\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 15:52:05.074754 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 15:52:05.075716 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 15:52:05.076457 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 15:52:05.077270 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 15:52:05.078118 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 15:52:05.078959 139782624093952 saver.py:1145] *******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 1, Loss: 22.0047\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v1.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 32.1352\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 104.973\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 19.7153\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 12.909\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 78.1242\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 12.8918\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 12.849\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 12.8477\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 83.1341\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 15:55:19.131733 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 15:55:19.132477 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 15:55:19.133113 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 15:55:19.133913 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 15:55:19.134535 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 15:55:19.135265 139782624093952 saver.py:1145] *******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 2, Loss: 83.1341\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v2.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 12.9926\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 47.0766\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 13.346\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 92.4446\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 13.6779\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 13.2202\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 12.8539\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 13.0587\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 12.9607\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 15:58:31.631829 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 15:58:31.632791 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 15:58:31.633432 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 15:58:31.634193 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 15:58:31.635042 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 15:58:31.635889 139782624093952 saver.py:1145] *******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 3, Loss: 12.9607\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v3.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 12.965\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 12.8687\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 12.6556\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 63.1005\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 93.2605\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 24.5863\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 12.5944\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 12.6056\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 19.0452\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 16:01:46.426129 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 16:01:46.427107 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 16:01:46.427806 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 16:01:46.428611 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 16:01:46.429296 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 16:01:46.430005 139782624093952 saver.py:1145] *******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 4, Loss: 19.0452\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v4.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 12.5612\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 12.5636\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 13.6158\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 12.6393\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 12.5594\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 12.5822\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 12.5325\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 12.5259\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 44.4733\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 16:04:58.932299 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 16:04:58.933096 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 16:04:58.933725 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 16:04:58.934549 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 16:04:58.935372 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 16:04:58.936202 139782624093952 saver.py:1145] *******************************************************\n",
      "W1019 16:04:59.098796 139782624093952 deprecation.py:323] From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 5, Loss: 44.4733\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v5.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 15.4412\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 12.5493\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 71.0539\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 12.6227\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 18.9201\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 136.006\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 12.7843\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 12.8565\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 12.6463\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 16:08:13.250410 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 16:08:13.251204 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 16:08:13.251811 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 16:08:13.252570 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 16:08:13.253430 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 16:08:13.254254 139782624093952 saver.py:1145] *******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 6, Loss: 12.6463\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v6.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 15.4209\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 12.8879\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 12.4097\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 12.5615\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 12.4093\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 13.4298\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 12.374\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 12.386\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 12.3559\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 16:11:27.648013 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 16:11:27.648979 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 16:11:27.649639 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 16:11:27.650284 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 16:11:27.650927 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 16:11:27.651661 139782624093952 saver.py:1145] *******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 7, Loss: 12.3559\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v7.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 12.3497\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 12.3435\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 13.4091\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 13.7704\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 12.3424\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 12.4024\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 12.3479\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 12.3451\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 12.3941\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 16:14:39.155929 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 16:14:39.156897 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 16:14:39.157544 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 16:14:39.158250 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 16:14:39.158948 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 16:14:39.159858 139782624093952 saver.py:1145] *******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 8, Loss: 12.3941\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v8.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 12.4521\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 12.4094\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 12.6454\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 12.6367\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 12.7004\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 12.908\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 12.7637\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 12.7729\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 12.3345\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 16:17:52.443330 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 16:17:52.444126 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 16:17:52.444848 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 16:17:52.445674 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 16:17:52.446545 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 16:17:52.447367 139782624093952 saver.py:1145] *******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 9, Loss: 12.3345\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v9.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 12.4947\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 16.0836\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 14.507\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 12.3854\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 12.2952\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 13.302\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 12.2422\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 12.2453\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 12.2333\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 16:21:03.696011 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 16:21:03.696962 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 16:21:03.697698 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 16:21:03.698552 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 16:21:03.699371 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 16:21:03.700202 139782624093952 saver.py:1145] *******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 10, Loss: 12.2333\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v10.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 12.2215\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 12.2176\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 13.2856\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 12.2565\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 12.2461\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 12.2776\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 12.2357\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 12.2283\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 12.2508\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 16:24:17.204774 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 16:24:17.205601 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 16:24:17.206137 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 16:24:17.206726 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 16:24:17.207464 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 16:24:17.208086 139782624093952 saver.py:1145] *******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 11, Loss: 12.2508\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v11.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 12.3769\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 12.3115\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 12.3821\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 12.6891\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 12.4324\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 12.9749\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 12.6689\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 12.587\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 12.2666\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 16:27:29.544183 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 16:27:29.544966 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 16:27:29.545555 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 16:27:29.546124 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 16:27:29.546786 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 16:27:29.547393 139782624093952 saver.py:1145] *******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 12, Loss: 12.2666\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v12.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 12.4634\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 12.6435\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 12.1928\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 12.2448\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 12.2632\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 13.2202\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 12.1608\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 12.1499\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 12.1667\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 16:30:42.472920 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 16:30:42.473911 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 16:30:42.474526 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 16:30:42.475130 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 16:30:42.475883 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 16:30:42.476577 139782624093952 saver.py:1145] *******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 13, Loss: 12.1667\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v13.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 12.143\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 12.1401\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 13.1226\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 20.6554\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 12.1715\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 12.1843\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 12.1834\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 12.155\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 12.171\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 16:33:56.601176 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 16:33:56.602155 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 16:33:56.602871 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 16:33:56.603726 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 16:33:56.604570 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 16:33:56.605426 139782624093952 saver.py:1145] *******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 14, Loss: 12.171\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v14.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 12.2347\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 12.3331\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 12.1825\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 12.7086\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 12.2364\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 13.0892\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 12.6037\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 12.2805\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 12.4717\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 16:37:08.021353 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 16:37:08.022102 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 16:37:08.022741 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 16:37:08.023336 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 16:37:08.023955 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 16:37:08.024595 139782624093952 saver.py:1145] *******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 15, Loss: 12.4717\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v15.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 12.3972\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 12.4594\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 12.2753\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 12.1292\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 12.2679\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 13.1677\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 12.1113\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 12.0983\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 12.1189\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 16:40:21.067788 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 16:40:21.068673 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 16:40:21.069350 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 16:40:21.070024 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 16:40:21.070677 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 16:40:21.071341 139782624093952 saver.py:1145] *******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 16, Loss: 12.1189\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v16.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 12.0938\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 12.0918\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 12.1029\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 13.1661\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 12.1423\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 12.1298\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 12.1484\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 12.112\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 12.1133\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 16:43:32.382425 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 16:43:32.383230 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 16:43:32.384417 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 16:43:32.385147 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 16:43:32.385854 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 16:43:32.386527 139782624093952 saver.py:1145] *******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 17, Loss: 12.1133\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v17.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 12.1836\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 12.272\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 12.1526\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 12.6119\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 12.2479\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 12.8662\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 12.5923\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 12.3985\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 12.4783\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 16:46:45.225691 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 16:46:45.226478 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 16:46:45.227021 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 16:46:45.227612 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 16:46:45.228346 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 16:46:45.229040 139782624093952 saver.py:1145] *******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 18, Loss: 12.4783\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v18.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 12.3163\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 12.1658\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 12.5445\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 12.083\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 12.241\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 12.1494\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 13.065\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 12.0687\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 12.087\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 16:49:58.781914 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 16:49:58.782706 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 16:49:58.783249 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 16:49:58.783839 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 16:49:58.784576 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 16:49:58.785196 139782624093952 saver.py:1145] *******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 19, Loss: 12.087\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v19.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 12.0622\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 12.0611\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 12.0601\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 13.1303\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 12.1299\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 12.072\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 12.14\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 12.087\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 12.0896\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 16:53:11.299014 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 16:53:11.299808 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 16:53:11.300405 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 16:53:11.301191 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 16:53:11.302059 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 16:53:11.302896 139782624093952 saver.py:1145] *******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 20, Loss: 12.0896\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v20.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 12.1427\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 12.2082\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 12.1654\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 12.4313\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 12.3797\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 12.5597\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 12.596\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 12.5382\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 12.5535\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 16:56:25.624366 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 16:56:25.625160 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 16:56:25.625881 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 16:56:25.626670 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 16:56:25.627481 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 16:56:25.628305 139782624093952 saver.py:1145] *******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 21, Loss: 12.5535\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v21.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 12.1367\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 12.2674\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 12.5525\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 12.0555\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 12.1923\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 12.09\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 13.1078\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 12.0517\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 12.0597\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 16:59:36.865145 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 16:59:36.866033 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 16:59:36.866858 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 16:59:36.867709 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 16:59:36.868523 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 16:59:36.869411 139782624093952 saver.py:1145] *******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 22, Loss: 12.0597\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v22.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 12.0476\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 12.0405\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 12.0396\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 13.1107\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 12.0864\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 12.0746\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 12.1145\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 12.0694\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 12.068\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 17:02:49.734137 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 17:02:49.735302 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 17:02:49.735994 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 17:02:49.736550 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 17:02:49.737181 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 17:02:49.737821 139782624093952 saver.py:1145] *******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 23, Loss: 12.068\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v23.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 12.1069\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 12.2101\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 12.153\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 12.2364\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 12.536\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 12.2916\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 12.8255\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 12.5279\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 12.4711\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 17:06:01.881612 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 17:06:01.882417 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 17:06:01.883014 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 17:06:01.883623 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 17:06:01.884329 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 17:06:01.884947 139782624093952 saver.py:1145] *******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 24, Loss: 12.4711\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v24.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 12.1077\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 12.3294\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 12.5089\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 12.0625\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 12.1479\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 12.1054\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 13.0951\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n",
      "Trained: 260 images\n",
      "Trained: 264 images\n",
      "Trained: 268 images\n",
      "Trained: 272 images\n",
      "Trained: 276 images\n",
      "Trained: 280 images\n",
      "Trained: 284 images\n",
      "Validation: 284 images\n",
      "Loss After Each Validation : 12.0383\n",
      "Trained: 288 images\n",
      "Trained: 292 images\n",
      "Trained: 296 images\n",
      "Trained: 300 images\n",
      "Trained: 304 images\n",
      "Trained: 308 images\n",
      "Trained: 312 images\n",
      "Trained: 316 images\n",
      "Trained: 320 images\n",
      "Trained: 324 images\n",
      "Validation: 324 images\n",
      "Loss After Each Validation : 12.0306\n",
      "Trained: 328 images\n",
      "Trained: 332 images\n",
      "Trained: 336 images\n",
      "Trained: 340 images\n",
      "Trained: 344 images\n",
      "Trained: 348 images\n",
      "Trained: 352 images\n",
      "Trained: 356 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1019 17:09:14.391766 139782624093952 saver.py:1140] *******************************************************\n",
      "W1019 17:09:14.392562 139782624093952 saver.py:1141] TensorFlow's V1 checkpoint format has been deprecated.\n",
      "W1019 17:09:14.393280 139782624093952 saver.py:1142] Consider switching to the more efficient V2 format:\n",
      "W1019 17:09:14.394124 139782624093952 saver.py:1143]    `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "W1019 17:09:14.394955 139782624093952 saver.py:1144] now on by default.\n",
      "W1019 17:09:14.395779 139782624093952 saver.py:1145] *******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained: 360 images\n",
      "Epoch: 25, Loss: 12.0306\n",
      "Model saved in file: ./MODELS/save_2/model_3dcnn_v25.ckpt\n",
      "Trained: 4 images\n",
      "Validation: 4 images\n",
      "Loss After Each Validation : 12.0467\n",
      "Trained: 8 images\n",
      "Trained: 12 images\n",
      "Trained: 16 images\n",
      "Trained: 20 images\n",
      "Trained: 24 images\n",
      "Trained: 28 images\n",
      "Trained: 32 images\n",
      "Trained: 36 images\n",
      "Trained: 40 images\n",
      "Trained: 44 images\n",
      "Validation: 44 images\n",
      "Loss After Each Validation : 12.0261\n",
      "Trained: 48 images\n",
      "Trained: 52 images\n",
      "Trained: 56 images\n",
      "Trained: 60 images\n",
      "Trained: 64 images\n",
      "Trained: 68 images\n",
      "Trained: 72 images\n",
      "Trained: 76 images\n",
      "Trained: 80 images\n",
      "Trained: 84 images\n",
      "Validation: 84 images\n",
      "Loss After Each Validation : 12.025\n",
      "Trained: 88 images\n",
      "Trained: 92 images\n",
      "Trained: 96 images\n",
      "Trained: 100 images\n",
      "Trained: 104 images\n",
      "Trained: 108 images\n",
      "Trained: 112 images\n",
      "Trained: 116 images\n",
      "Trained: 120 images\n",
      "Trained: 124 images\n",
      "Validation: 124 images\n",
      "Loss After Each Validation : 13.0902\n",
      "Trained: 128 images\n",
      "Trained: 132 images\n",
      "Trained: 136 images\n",
      "Trained: 140 images\n",
      "Trained: 144 images\n",
      "Trained: 148 images\n",
      "Trained: 152 images\n",
      "Trained: 156 images\n",
      "Trained: 160 images\n",
      "Trained: 164 images\n",
      "Validation: 164 images\n",
      "Loss After Each Validation : 12.0744\n",
      "Trained: 168 images\n",
      "Trained: 172 images\n",
      "Trained: 176 images\n",
      "Trained: 180 images\n",
      "Trained: 184 images\n",
      "Trained: 188 images\n",
      "Trained: 192 images\n",
      "Trained: 196 images\n",
      "Trained: 200 images\n",
      "Trained: 204 images\n",
      "Validation: 204 images\n",
      "Loss After Each Validation : 12.0601\n",
      "Trained: 208 images\n",
      "Trained: 212 images\n",
      "Trained: 216 images\n",
      "Trained: 220 images\n",
      "Trained: 224 images\n",
      "Trained: 228 images\n",
      "Trained: 232 images\n",
      "Trained: 236 images\n",
      "Trained: 240 images\n",
      "Trained: 244 images\n",
      "Validation: 244 images\n",
      "Loss After Each Validation : 12.0793\n",
      "Trained: 248 images\n",
      "Trained: 252 images\n",
      "Trained: 256 images\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(num):\n",
    "        Xs=[]\n",
    "        Ys=[]\n",
    "        for j in range(5):\n",
    "            xs, ys = LoadTrainBatch(batch_size) # xs = [100,66,200,3]\n",
    "            Xs.append(xs)\n",
    "            Ys.append(ys)\n",
    "        Xs= np.array(Xs) #Xs[5,100,66,200,3]\n",
    "        Ys = np.array(Ys)\n",
    "        train_step.run(feed_dict={model.x: Xs, model.y_: Ys})\n",
    "        print(\"Trained: %d images\" % ((i+1)*j))\n",
    "\n",
    "        \n",
    "        if i%10==0:\n",
    "            X_val=[]\n",
    "            Y_val=[]\n",
    "            for j in range(5):\n",
    "                xs, ys = LoadValBatch(batch_size)\n",
    "                X_val.append(xs)\n",
    "                Y_val.append(ys)\n",
    "            Y_val= np.array(Y_val) #Xs[454,100,66,200,3]\n",
    "            X_val = np.array(X_val)   \n",
    "            loss_value = loss.eval(feed_dict={model.x:X_val,model.y_: Y_val})\n",
    "            print(\"Validation: %d images\" % ((i+1)*j))\n",
    "            print(\"Loss After Each Validation : %g\" % (loss_value))\n",
    "            summary = merged_summary_op.eval(feed_dict={model.x:X_val, model.y_: Y_val})\n",
    "            summary_writer.add_summary(summary, epoch * num + i)\n",
    "    \n",
    "    print(\"Epoch: %d, Loss: %g\" % (epoch, loss_value))\n",
    "    if not os.path.exists(LOGDIR):\n",
    "        os.makedirs(LOGDIR)\n",
    "    path_str=\"model_3dcnn_v\"+str(epoch)+\".ckpt\"\n",
    "    checkpoint_path = os.path.join(LOGDIR,path_str)\n",
    "    filename = saver.save(sess, checkpoint_path)\n",
    "    print(\"Model saved in file: %s\" % filename)\n",
    "        \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kpq0NbXCO-T3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Train_Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
